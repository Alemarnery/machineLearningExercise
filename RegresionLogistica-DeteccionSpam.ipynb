{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones complementarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina el codigo HTML de los correos\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función se encarga de elimar los tags HTML que se encuentren en el texto del correo electrónico\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de eliminación de los tags HTML de un texto\n",
    "t = '<tr><td align=\"left\"><a href=\"../../issues/51/16.html#article\">Phrack World News</a></td>'\n",
    "strip_tags(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de eliminar los posibles tags HTML que se encuentren en el correo electrónico, deben realizarse otras acciones de preprocesamiento para evitar que los mensajes contengan ruido innecesario. Entre ellas se encuentra la eliminación de los signos de puntuación, eliminación de posibles campos del correo electrónico que no son relevantes o eliminación de los afijos de una palabra manteniendo únicamente la raiz de la misma (Stemming). La clase que se muestra a continuación realiza estas transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39memail\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mParser\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import email\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "class Parser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        self.punctuation = list(string.punctuation)\n",
    "\n",
    "    def parse(self, email_path):\n",
    "        \"\"\"Parse an email.\"\"\"\n",
    "        with open(email_path, errors='ignore') as e:\n",
    "            msg = email.message_from_file(e)\n",
    "        return None if not msg else self.get_email_content(msg)\n",
    "\n",
    "    def get_email_content(self, msg):\n",
    "        \"\"\"Extract the email content.\"\"\"\n",
    "        subject = self.tokenize(msg['Subject']) if msg['Subject'] else []\n",
    "        body = self.get_email_body(msg.get_payload(),\n",
    "                                   msg.get_content_type())\n",
    "        content_type = msg.get_content_type()\n",
    "        # Returning the content of the email\n",
    "        return {\"subject\": subject,\n",
    "                \"body\": body,\n",
    "                \"content_type\": content_type}\n",
    "\n",
    "    def get_email_body(self, payload, content_type):\n",
    "        \"\"\"Extract the body of the email.\"\"\"\n",
    "        body = []\n",
    "        if type(payload) is str and content_type == 'text/plain':\n",
    "            return self.tokenize(payload)\n",
    "        elif type(payload) is str and content_type == 'text/html':\n",
    "            return self.tokenize(strip_tags(payload))\n",
    "        elif type(payload) is list:\n",
    "            for p in payload:\n",
    "                body += self.get_email_body(p.get_payload(),\n",
    "                                            p.get_content_type())\n",
    "        return body\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Transform a text string in tokens. Perform two main actions,\n",
    "        clean the punctuation symbols and do stemming of the text.\"\"\"\n",
    "        for c in self.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = list(filter(None, text.split(\" \")))\n",
    "        # Stemming of the tokens\n",
    "        return [self.stemmer.stem(w) for w in tokens if w not in self.stopwords]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
